# FastAPI和大数据



```python
from typing import Optional
from fastapi import FastAPI
from pydantic import BaseModel
import pyhdfs   # hdfs
from pyhive import hive     # hive

app = FastAPI()

'''
连接hdfs
'''
fs = pyhdfs.HdfsClient(hosts='localhost:9870', user_name='root')  # user_name就linux用户，我这里是root
connection = hive.connect(host='localhost',
                          port=10000,
                          database='gmall')
'''
连接hive
'''
query="select * from ods_sku_info"  # 查询
cur = connection.cursor()
cur.execute(query)
res = cur.fetchall()

class Item(BaseModel):
    name: str
    price: float
    is_offer: Optional[bool] = None

@app.get("/")
def read_root():
    result = fs.listdir('/')
    return {"你好": "清数研究院"}, {"hive": "查询"}, {"hdfs": result}, {"hive查询到gmall.ods_sku_info的结果为":res}
```





## 参考

### hdfs

```python
import pyhdfs

fs = pyhdfs.HdfsClient(hosts='localhost:9870', user_name='root')  # user_name就linux用户，我这里是root
# home_directory = fs.get_home_directory()  # 返回这个用户的根目录
# fs_name_node = fs.get_active_namenode()  # 返回可用的namenode节点
# # print(home_directory)
# # print(fs_name_node)
# print(fs.listdir('/'))
# response_file = fs.open('/test.txt')
# print(response_file.read())
# fs.append('/test.txt', 'i love you')
# open_file = fs.open('/test.txt').read()
# print(open_file.readlines())

# print(fs.list_status('/test.txt'))
# print(fs.get_file_checksum('/test.txt'))
# print(fs.listdir('/'))
# fs.copy_to_local('/test.txt', 'test.txt')
# fs.create('/test02.txt', b'222')
# print(fs.open('/test02.txt').read())
# file = fs.get_file_status('/software/hadoop-2.6.0-cdh5.9.3.tar.gz')
# print(file)
# print(type(file))
# print(file.accessTime)
# print(fs.get_file_status('/test02.txt'))
# print(fs.exists('/'))
# fs.copy_from_local('test003.txt',
#                    '/software/test005.txt')
# print(fs.listdir('/software'))
# print(fs.delete('/software/test001.txt'))
# print(fs.listdir('/software'))
# test005 = fs.get_file_status('/software/test005.txt')
# software = fs.get_file_status('/software')
# print(test005)
# print(test005.type)
# print(software.type)
# print(len(fs.list_status('/software/test005.txt')))
# print(len(fs.list_status('/')))
# fs.copy_to_local('/software/hadoop-2.6.0-cdh5.9.3.tar.gz', 'hadoop-2.6.0-cdh5.9.3.tar.gz')
# print(fs.open('/software/test004.txt').read())
# fs.create_symlink()
# fs.create('/software/test001.txt', b'11')
# print(fs.get_file_status('/software/test005.txt'))
# fs.concat(target='/software/test001.txt', sources=['/software/test004.txt', '/software/test003.txt'])
# print(fs.listdir('/software'))
# fs.create('/test/a.txt', b'111')
# fs.create('/test/b.txt', b'222')
# fs.create('/test/c.txt', b'333')
# fs.delete('/test/')
# print(fs.get_home_directory())
# print(fs.get_file_checksum('/test/a.txt'))
# print(fs.set_xattr('/test/a.txt', '/test/d.txt', flag= 'test_name'))
# print(fs.listdir('/test'))
# print(fs.list_status('/tests'))
# print(fs.get_file_status('/tests'))
# print(fs.mkdirs('/tests'))
# print(fs.listdir('/test'))
# fs.rename('/test/a.txt', '/test/d.txt')
# fs.rename_snapshot('/tests', 'tests', 'testb')
# fs.delete('/tests')
# print(fs.listdir('/'))
# fs.mkdirs('/tests')
# fs.create('/testa/a.txt', b'HDFS')
# fs.create('/tests/b.txt', b'HDFS-B')
# fs.create('/tests/C.txt', b'HDFS-C')
# print(fs.listdir('/tests'))
# path = '/tests'
# file_names = fs.listdir(path)
# remove_names = []
# if file_names:
#     for file_name in file_names:
#         remove_names.append(path + '/' + file_name)
#
#     for remove_file in remove_names:
#         fs.delete(remove_file)
#     print(remove_names)
# print(fs.listdir('/tests'))
# fs.delete(path)
# fs.rename('/tests', '/tests1')
print(fs.listdir('/'))
# fs.copy_to_local('/test.txt', 'test.txt')
# fs.copy_from_local('test.txt', '/test/test.txt')
# fs.mkdirs('/test')
# print(fs.listdir('/'))
```

### hive

```python
from pyhive import hive

connection = hive.connect(host='localhost',
                          port=10000,
                          database='gmall')

query="select * from ods_sku_info"
cur = connection.cursor()
cur.execute(query)
res = cur.fetchall()

print(res)
```

