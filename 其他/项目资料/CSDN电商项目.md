项目是类电商网站，从前端给予spring mvc架构的前端业态展现，以及spring与hibernate在servlet3.0规范下的
纯注解编程体验，迅捷完成复杂业务流程的编程实现处理。网站通篇采用maven实现项目依赖管理，更有三方插件
在应用过程中的使用便捷扩展与使用。

更有从项目运维角度上涉及的nginx服务器的负载均衡实现与动静分离技术中同tomcat服务器的服务器集群整合。
其中更是牵涉到操作系统层面上的优化处理，比如立竿见影的cpu affinity进程分配技术以及粒度更细的cgroup
实现资源隔离，此类皆为企业生产过程应用的典型技术手段。

大数据方面从日志数据的产生，比如通过ab压力测试软件生产的海量日志消息，以及通过flume进行hop式跳跃推送
进行kafka消息集群，同实现原生数据的hdfs下沉处理与MR实现的数据清洗过程后的数据转储。
使用hive与crontab组合实现网站流量的KPI数据定时统计。高可用方面配置独立的zk集群实现Hadoop的NN、RM以及

利用storm实现业务数据的在线实时处理，结合hbase实现数据的实时读写。
高可用方向使用独立的zk集群完成Hadoop的NN、RM以及Hbase中Master节点的高可用处理，以避免单点故障。



1.项目描述，核心技术说明，业务流程分析，项目整体架构图解。

2.项目初始化
  基于servler3.0 的web层框架准备，springmvc+spring+hibernate的基础类库
  实现。
3.nginx服务器反向代理配置，
  nginx + tomcat实现动静资源隔离。
  nginx实现日志滚动。
  使用Apache ab进行压力测试。
4.部署flume和kafka集群。
  配置hive数据仓库，使用linux调度方式周期性生成分区表。
  利用spooldir source提取nginx滚动生成的日志文件到kafka集群。
  实现kafka消费者，数据分成两部分处理，一部分作为原生数据直接sink到hdfs，作为备份。
  另一部分进行数据清洗，并将清洗后的数据写入到hive数据库的分区表中。
5.配置hbase集群，实现业务数据例如用户信息，订单信息等精准数据的存储和查询。
  在hive中创建pv，uv等数据统计表，使用hbase存储处理器将数据映射到hbase中，以方便于快速查询和
  数据可视化处理。
  配置linux计划任务，周期性调用hive脚本，对上一天的日志信息进行kpi统计，统计结果进入hbase映射表中。
  集合web前端部分，对hbase库中数据进行展现和可视化处理。